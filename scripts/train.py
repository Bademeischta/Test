#!/usr/bin/env python
"""Minimal training harness for the chess AI."""
import argparse
import torch

from chess_ai.config import Config
from chess_ai.game_environment import GameEnvironment
from chess_ai.policy_value_net import PolicyValueNet
from chess_ai.replay_buffer import ReplayBuffer
from chess_ai.self_play import run_self_play
from chess_ai.trainer import Trainer
from chess_ai.action_index import ACTION_SIZE
from chess_ai.network_manager import NetworkManager


def load_or_initialize_network(manager: NetworkManager):
    net = PolicyValueNet(
        GameEnvironment.NUM_CHANNELS,
        ACTION_SIZE,
        num_blocks=Config.NUM_RES_BLOCKS,
        filters=Config.NUM_FILTERS,
    ).to(Config.DEVICE)
    optimizer = torch.optim.SGD(
        net.parameters(),
        lr=Config.LEARNING_RATE,
        momentum=Config.MOMENTUM,
        weight_decay=Config.WEIGHT_DECAY,
    )
    ckpt = manager.latest_checkpoint()
    if ckpt:
        data = torch.load(ckpt, map_location=Config.DEVICE)
        net.load_state_dict(data["model_state"])
        optimizer.load_state_dict(data["optim_state"])
    return net, optimizer


def main(args):
    manager = NetworkManager()
    net, optimizer = load_or_initialize_network(manager)
    buffer = ReplayBuffer()

    for g in range(args.games):
        for state, policy, value in run_self_play(net, num_simulations=args.simulations):
            buffer.add(state, policy, value)
    trainer = Trainer(net, buffer, optimizer, epochs=args.epochs)
    trainer.train()
    manager.save(net, optimizer, "latest")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run minimal training loop")
    parser.add_argument("--games", type=int, default=1, help="Number of self-play games")
    parser.add_argument("--epochs", type=int, default=1, help="Training epochs")
    parser.add_argument("--simulations", type=int, default=Config.NUM_SIMULATIONS, help="MCTS simulations")
    main(parser.parse_args())
